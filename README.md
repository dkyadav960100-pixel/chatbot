# ğŸ¤– GenAI Telegram Bot

A **Hybrid RAG + Vision** Telegram Bot that can answer questions from a knowledge base and describe uploaded images.

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![Telegram](https://img.shields.io/badge/Telegram-Bot-blue.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)

## ğŸ¯ Features

### ğŸ“š RAG (Retrieval-Augmented Generation)
- Answer questions from your custom knowledge base
- Semantic search using sentence-transformers embeddings
- SQLite vector store for persistent storage
- Context-aware responses with source citations
- Supports Markdown, TXT, JSON, and PDF documents

### ğŸ–¼ï¸ Vision/Image Description
- Describe uploaded images using BLIP model
- Generate relevant tags for images
- Support for JPG, PNG, WEBP, GIF formats
- Configurable caption length and tag count

### ğŸ’¡ Smart Features
- **Conversation History**: Remembers last 3 interactions per user
- **Query Caching**: Fast responses for repeated queries
- **Multi-LLM Support**: Ollama (primary) with OpenAI fallback
- **Session Management**: Per-user context and preferences
- **Source Citations**: Shows which documents were used

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Telegram Bot Interface                      â”‚
â”‚                    (python-telegram-bot)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                             â”‚
            â–¼                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     RAG System        â”‚     â”‚    Vision System      â”‚
â”‚                       â”‚     â”‚                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Document Loader â”‚  â”‚     â”‚  â”‚ Image Processor â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â–¼           â”‚     â”‚           â–¼           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Text Chunker   â”‚  â”‚     â”‚  â”‚  BLIP Model     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚     â”‚  â”‚  (Captioning)   â”‚  â”‚
â”‚           â–¼           â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚     â”‚           â–¼           â”‚
â”‚  â”‚  Embeddings     â”‚  â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ (MiniLM-L6-v2)  â”‚  â”‚     â”‚  â”‚   Tag Extractor â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â–¼           â”‚     â”‚                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â”‚  Vector Store   â”‚  â”‚
â”‚  â”‚   (SQLite)      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â–¼           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    Retriever    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               LLM Handler                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Ollama (Local) â”‚  â”‚  OpenAI API (Fallback)  â”‚ â”‚
â”‚  â”‚  - LLaMA 3      â”‚  â”‚  - GPT-3.5/4            â”‚ â”‚
â”‚  â”‚  - Mistral      â”‚  â”‚                         â”‚ â”‚
â”‚  â”‚  - Phi-3        â”‚  â”‚                         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Storage Layer                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Query Cache    â”‚  â”‚  Session Manager        â”‚ â”‚
â”‚  â”‚   (SQLite)      â”‚  â”‚  (In-Memory)            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


## App Link : https://dkyadav960100-pixel-chatbot-streamlit-app-mbmm25.streamlit.app/

---
## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- Telegram Bot Token (from [@BotFather](https://t.me/BotFather))
- [Ollama](https://ollama.ai/) (recommended) or OpenAI API key

### Option 1: Local Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/genai-telegram-bot.git
cd genai-telegram-bot

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# For CPU-only (smaller download):
pip install -r requirements-cpu.txt

# Configure environment
cp .env.example .env
# Edit .env and add your TELEGRAM_BOT_TOKEN

# Start Ollama (in another terminal)
ollama serve
ollama pull llama3.2:1b

# Run the bot
python app.py
```

### Option 2: Docker Compose (Recommended)

```bash
# Clone and configure
git clone https://github.com/yourusername/genai-telegram-bot.git
cd genai-telegram-bot
cp .env.example .env
# Edit .env and add your TELEGRAM_BOT_TOKEN

# Start everything
docker-compose up -d

# View logs
docker-compose logs -f bot
```

## ğŸ“‹ Bot Commands

| Command | Description |
|---------|-------------|
| `/start` | Welcome message and bot introduction |
| `/help` | Show all available commands |
| `/ask <question>` | Ask a question from the knowledge base |
| `/image` | Get ready to describe an uploaded image |
| `/summarize` | Summarize the last interaction |
| `/status` | Show bot status and statistics |
| `/clear` | Clear conversation history |

### Usage Examples

**RAG Query:**
```
/ask What is the refund policy?
```

**Image Description:**
Send any image directly or use `/image` first.

**Natural Conversation:**
Just type your question without any command!

## ğŸ“ Project Structure

```
genai_telegram_bot/
â”œâ”€â”€ app.py                 # Main entry point
â”œâ”€â”€ config.py              # Configuration management
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ Dockerfile             # Docker build file
â”œâ”€â”€ docker-compose.yml     # Docker Compose configuration
â”œâ”€â”€ .env.example           # Environment variables template
â”‚
â”œâ”€â”€ bot/                   # Telegram bot module
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ bot.py            # Bot implementation
â”‚
â”œâ”€â”€ rag/                   # RAG system
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ document_loader.py # Load documents
â”‚   â”œâ”€â”€ chunker.py        # Text chunking
â”‚   â”œâ”€â”€ embeddings.py     # Embedding generation
â”‚   â”œâ”€â”€ vector_store.py   # SQLite vector storage
â”‚   â””â”€â”€ retriever.py      # RAG retrieval logic
â”‚
â”œâ”€â”€ vision/                # Vision system
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ image_processor.py # Image preprocessing
â”‚   â”œâ”€â”€ caption_model.py  # BLIP captioning
â”‚   â””â”€â”€ vision_handler.py # Main vision interface
â”‚
â”œâ”€â”€ llm/                   # LLM handling
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ llm_handler.py    # Ollama/OpenAI integration
â”‚
â”œâ”€â”€ utils/                 # Utilities
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cache.py          # Query caching
â”‚   â””â”€â”€ session.py        # User session management
â”‚
â”œâ”€â”€ knowledge_base/        # Your documents go here
â”‚   â”œâ”€â”€ company_policies.md
â”‚   â”œâ”€â”€ product_faq.md
â”‚   â”œâ”€â”€ technical_docs.md
â”‚   â”œâ”€â”€ refund_policy.md
â”‚   â””â”€â”€ getting_started.md
â”‚
â””â”€â”€ data/                  # Generated data (auto-created)
    â”œâ”€â”€ vector_store.db   # Embeddings database
    â””â”€â”€ cache.db          # Query cache
```

## âš™ï¸ Configuration

### Environment Variables

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `TELEGRAM_BOT_TOKEN` | âœ… | - | Your Telegram bot token |
| `OLLAMA_BASE_URL` | âŒ | `http://localhost:11434` | Ollama API URL |
| `OLLAMA_MODEL` | âŒ | `llama3.2:1b` | Ollama model name |
| `OPENAI_API_KEY` | âŒ | - | OpenAI API key (fallback) |
| `OPENAI_MODEL` | âŒ | `gpt-3.5-turbo` | OpenAI model |
| `VISION_MODEL` | âŒ | `blip` | Vision model (`blip`, `blip2`, `git`) |
| `DEVICE` | âŒ | `cpu` | Device (`cpu` or `cuda`) |
| `DEBUG` | âŒ | `false` | Enable debug mode |

### Recommended LLM Models

**For Ollama (Local):**
- `llama3.2:1b` - Fast, good quality (recommended)
- `phi3:mini` - Very small, decent quality
- `mistral:7b-instruct` - Best quality, requires more RAM
- `llama3.1:8b` - Good balance of speed and quality

**For OpenAI:**
- `gpt-3.5-turbo` - Fast and cost-effective
- `gpt-4` - Best quality, higher cost

## ğŸ“š Knowledge Base

Add your documents to the `knowledge_base/` directory:

### Supported Formats
- **Markdown** (`.md`) - Recommended
- **Plain Text** (`.txt`)
- **JSON** (`.json`)
- **PDF** (`.pdf`) - Requires PyPDF2

### Document Tips
1. Use clear headings for better semantic chunking
2. Keep documents focused on specific topics
3. Include relevant keywords and terms
4. Use consistent formatting

### Re-indexing Documents

After adding new documents:
```bash
python app.py --init-kb
```

## ğŸ”§ Advanced Configuration

### Custom Embedding Model

```python
# In config.py or via environment
EMBEDDING_MODEL = "sentence-transformers/all-mpnet-base-v2"  # Higher quality
EMBEDDING_MODEL = "BAAI/bge-small-en-v1.5"  # Alternative
```

### Chunking Strategy

```python
# In rag/retriever.py
chunker = TextChunker(
    chunk_size=500,        # Characters per chunk
    chunk_overlap=50,      # Overlap between chunks
    strategy=ChunkingStrategy.PARAGRAPH  # Or SENTENCE, SEMANTIC
)
```

### Vision Model Selection

| Model | Quality | Speed | Memory |
|-------|---------|-------|--------|
| `blip` | Good | Fast | ~1GB |
| `blip2` | Better | Slower | ~3GB |
| `git` | Good | Fast | ~1GB |

## ğŸ³ Docker Deployment

### Production Deployment

```bash
# Build and start
docker-compose up -d --build

# Scale bot instances (if using webhook)
docker-compose up -d --scale bot=3

# View logs
docker-compose logs -f

# Stop
docker-compose down
```

### GPU Support

```yaml
# In docker-compose.yml, add to bot service:
deploy:
  resources:
    reservations:
      devices:
        - driver: nvidia
          count: 1
          capabilities: [gpu]
```

## ğŸ§ª Testing

```bash
# Run tests
pytest tests/

# With coverage
pytest --cov=. tests/

# Specific test
pytest tests/test_rag.py -v
```

## ğŸ“Š Monitoring

The bot provides a `/status` command showing:
- Active LLM provider
- Knowledge base statistics
- Active sessions
- Cache hit rate
